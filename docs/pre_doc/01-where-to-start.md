# どこから手を付けるべきか (最小の縦切り)

`context/request.md` のゴールは「複数Raspberry Pi + 複数カメラで反射球を検出し、ホストで3D復元→剛体推定→SteamVRへ5トラッカーを60fps程度で入力」です。

ここで一番の失敗パターンは、個別要素(検出、同期、三角測量、剛体推定、SteamVR出力)を並行で作り始めて、最後に接続・整合(座標系/時刻/レイテンシ)で崩壊することです。

最初に「動く縦切り」を作って観測可能にし、その上で精度と頑健性を上げるのが最短です。

## まず作る縦切り (Phase 0)

最初のゴールは「カメラやPiが無くても、入力→推定→出力が一周する」ことです。

- **入力(ダミー/ログ再生)**: 2Dブロブ列(カメラID, timestamp, blobs[])を流せる
- **ホスト処理(最小)**: 2視点以上の点を三角測量して3D点群を得る
- **剛体(仮)**: 5つの剛体のうち、まずは1つ(例: 腰)だけを安定して推定
- **出力(仮)**: SteamVRへ送る代わりに、ローカルで pose を表示/ログ化

理由:
- まず **時刻・座標系・レイテンシ** を可視化できる状態にする必要がある
- ここが無いと、以降の改善(同期・フィルタ・クラスタリング・剛体推定)の効果測定ができない

## 次に作る縦切り (Phase 1)

`context/request.md` の分散構成に沿って「Pi→Host→Pi制御」を接続します。

- **Pi側**: 画像→ブロブ検出→(x,y,area)を1フレーム1メッセージで送る
- **Host側**: 受信→フレームペアリング→三角測量→フィルタ→剛体推定
- **Host→Pi制御**: start/stop、露光/ゲイン、LEDのON/OFF

ここで重要なのは、精度よりも「欠損が起きても落ちない」「通信が乱れても復帰する」ことです。

## 実装の当たり所(参考実装)

先駆者( `references/jyjblrd/Low-Cost-Mocap` )は **Host側で外部カメラを扱う** 例ですが、以下のパーツは設計の雛形になります。

- キャリブレーション/三角測量/対応付け/BA: `references/jyjblrd/Low-Cost-Mocap/computer_code/api/helpers.py`
- カメラ姿勢推定のUI〜イベント: `references/jyjblrd/Low-Cost-Mocap/computer_code/src/App.tsx`
- Socket.IOイベントの口(Host側): `references/jyjblrd/Low-Cost-Mocap/computer_code/api/index.py`

## ここから着手する順番 (推奨)

1. **データ契約(プロトコル)を固定**: Pi→Hostメッセージ、Host→Pi制御、Host→SteamVR出力の最小スキーマを決める
2. **ログ/リプレイ基盤**: 入力を録画して再生できるようにする(デバッグ・性能計測の基礎)
3. **キャリブレーションのワークフロー**: 内部/外部パラメータ、座標系、保存形式
4. **対応付け→三角測量→再投影誤差の監視**: ここをメトリクス化(精度改善の軸)
5. **遮蔽対策(フィルタ/トラック管理)**: 1点ごとのKalman + ID維持
6. **剛体の推定**: クラスタリング + 既知マーカ配置からの姿勢推定
7. **SteamVR連携**: 最後に差し替え可能な出力モジュールとして実装
